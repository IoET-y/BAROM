Latent Space Learning for PDE Systems with Complex Boundary (BAROM)
 ## üìú Abstract
Latent space Reduced Order Models (ROMs) in Scientific Machine Learning (SciML) can enhance and accelerate Partial Differential Equation (PDE) simulations. However, they often struggle with complex boundary conditions (BCs) such as time-varying, nonlinear, or state-dependent ones. Current methods for handling BCs in latent space have limitations due to representation mismatch and projection difficulty, impacting predictive accuracy and physical consistency. To address this, we introduce BAROM (Boundary-Aware Attention ROM). BAROM integrates: (1) explicit, Reduced Basis Methods-inspired boundary treatment using a modified ansatz and a learnable lifting network for complex BCs; and (2) a non-intrusive, attention-based mechanism, inspired by Galerkin Neural Operators, to learn internal field dynamics within a POD-initialized latent space. Evaluations show BAROM achieves superior accuracy and robustness on benchmark PDEs with diverse complex BCs compared to established SciML approaches.
(Abstract from the provided LaTeX paper)

üìñ Overview
This repository contains the source code, datasets, and experimental setup for the Boundary-Aware Attention Reduced Order Model (BAROM), as presented in the paper "Latent Space Learning for PDE Systems with Complex Boundary." BAROM is a novel SciML framework designed for accurate and efficient simulation of PDE systems, particularly those featuring complex, dynamic, and feedback-dependent boundary conditions.

The core challenges addressed are the representation mismatch and projection difficulty when handling complex BCs in traditional latent space models. BAROM tackles these by:

Employing an explicit boundary-internal field decomposition (U=U 
B
‚Äã
 +U 
I
‚Äã
 ) inspired by Reduced Basis Methods (RBM).

Introducing a learnable lifting network (L 
lift
‚Äã
 ) to dynamically generate the boundary-conforming field U 
B
‚Äã
  from time-dependent boundary parameters P 
BC
‚Äã
 (t).

Developing a Boundary-Aware Attention (BAA) mechanism for the non-intrusive evolution of latent coefficients a(t) representing the internal field U 
I
‚Äã
 =Œ¶a(t). This evolution is explicitly conditioned on boundary parameters.

Two main variants of BAROM are explored in this work:

BAROM_ImpBC (Implicit Boundary Condition Handling): The influence of boundary conditions on the latent dynamics is primarily learned implicitly by the attention and FFN components.

BAROM_ExpBC (Explicit Boundary Condition Handling): This is the primary model detailed in the paper. It explicitly processes boundary parameters P 
BC
‚Äã
 (t 
k+1
‚Äã
 ) to directly inform the update of latent coefficients a(t 
k+1
‚Äã
 ), aligning closely with the theoretical formulation presented (e.g., Equation 9 in the paper).

‚öôÔ∏è The BAROM Framework (BAROM_ExpBC - Equation 9 Aligned Version)
The primary BAROM model, BAROM_ExpBC, is implemented in PDE_category2/BAROM_ExpBC.py. It is designed for robust handling of complex boundary conditions, including those with internal-boundary coupling and external controls.

Core Principles (Section 3 of the Paper)
Explicit Decomposition (Ansatz):
The solution  
U
^
  is decomposed as:
U
^
 (x,t;Œº)=U 
B
‚Äã
 (x,t;P 
BC
‚Äã
 (t),Œº)+U 
I
‚Äã
 (x,t;Œº)
(Eq. \ref{eq:barom_ansatz_methodology} in the paper)

Learnable Lifting Network (L 
lift
‚Äã
 ):
The boundary field U 
B
‚Äã
  is generated by the UniversalLifting class:
U 
B
‚Äã
 (x,t;P 
BC
‚Äã
 (t),Œº)=Llift(PBC(t),Œº;Œò 
L 
lift
‚Äã
 
‚Äã
 )(x)
(Eq. \ref{eq:lifting_network_methodology} in the paper)

Internal Field (U 
I
‚Äã
 ) Representation:
U 
I
‚Äã
 (x,t;Œº)‚âàŒ¶(x)a(t;Œº)
where Œ¶(x) are learnable, POD-initialized basis functions (parameter model.Phi) and a(t) are latent coefficients.
(Eq. \ref{eq:barom_internal_field_methodology} in the paper)

Latent Dynamics Evolution (F 
latent
‚Äã
 )
The evolution of latent coefficients a(t 
k
‚Äã
 )‚Üía(t 
k+1
‚Äã
 ) is central to BAROM_ExpBC and is implemented in the forward_step method of the MultiVarAttentionROM class (referred to as MultiVarAttentionROMEq9 in some benchmark scripts for clarity). This aligns with the structure of Equation (9) from the paper:
a 
n+1
 = 
A
^
 aa 
n
 + 
B
^
  
w
^
  
n
 + 
A
^
 BCU 
B
n
‚Äã
 ‚àíŒ¶ 
T
 U 
B
n+1
‚Äã
 

In the code, this is achieved by:
\mathbf{a}(t_{k+1}) = \mathbf{a}(t_k) + \Delta\mathbf{a}{\text{attn}} + \Delta\mathbf{a}{\text{ffn}} + \Delta\mathbf{a}_{\text{bc_explicit}} - \text{term_to_subtract_phiT_UBnp1}

Where:

a(t 
k
‚Äã
 ): Current latent state (a_n_var).

Œîa 
attn
‚Äã
 : Update from the multi-head attention mechanism (a_update_attn_val). This, along with the FFN term, learns the effects analogous to the operator  
A
^
  
a
‚Äã
 .

Œîa 
ffn
‚Äã
 : Update from a feed-forward network (alpha_var * ffn_update_intrinsic_val).

\Delta\mathbf{a}_{\text{bc_explicit}}: Update derived from processing P 
BC
‚Äã
 (t 
n
‚Äã
 ) (boundary conditions at the current time step n) via bc_feature_processor and bc_to_a_update layers (bc_driven_a_update_val). This term learns the influence analogous to  
B
^
  
w
^
  
n
 + 
A
^
 BCUB 
n
 .

term_to_subtract_phiT_UBnp1: Explicitly computed projection ‚àíŒ¶ 
T
 U 
B
n+1
‚Äã
 , where U 
B
n+1
‚Äã
 =Llift(PBC(t 
n+1
‚Äã
 )).

Reconstruction
The physical solution at the next time step is reconstructed as:
U
^
  
n+1
 =U 
B
n+1
‚Äã
 +Œ¶a 
n+1
 
(Implemented at the end of the forward_step method).

Refer to Section 3 of the paper for a detailed methodological description and Algorithm 1 for the predictive step.

üìÇ Repository Structure
The repository is organized into three main experimental categories:

PDE_category1/: Experiments with externally prescribed complex boundary conditions (no internal feedback).

PC1_datageneration/: Scripts for dataset generation (e.g., generate_datasets_PDE_task1.py).

datasets_full/: Dataset descriptions (e.g., dataset.md).

Training scripts for BAROM_ImpBC (BAROM_ImpBC.py) and baselines (e.g., FNO.py, SPFNO.py).

Benchmarking.py: Benchmarking script for this category.

command_line.md: Example commands.

PDE_category2/: Experiments with complex boundary conditions involving internal-boundary coupling and/or external control signals. This is the primary focus for the BAROM_ExpBC model.

generate_datasets_PDE_task2.py: Dataset generation script.

datasets_new_feedback/: Dataset descriptions (e.g., dataset.md).

BAROM_ExpBC.py: Main training script for the Equation 9-aligned BAROM.

BAROM_ImpBC.py: Training script for the implicit BAROM variant.

Baseline model implementations (e.g., SPFNO_FULL.py, BENO.py).

Benchmarking4GPu.py: Main benchmarking script for this category, including GPU performance metrics.

Specialized benchmarking scripts (e.g., BenchmarkingEBCBAROM-CDF.py).

command_line.md, datasetscript.md: Command examples and dataset details.

data_visualization.ipynb: Notebook for visualizing datasets.

Ablation_study/: Scripts and configurations for ablation studies.

Individual scripts for different ablations (e.g., BAROM_Non_attention.py, BAROM_Random_pod_initialize.py, BAROM_fixedlifting.py, BAROM_pod_dim_ablation.py).

Benchmarking scripts for ablation variants (e.g., Benchmarking_Noatten_BAROM.py, benchmarking.py).

ablation.md: Description of ablation studies.

Root Directory:

README.md: This file.

(Other potential shared utilities or configuration files)

üìä Datasets
The research utilizes synthetically generated datasets for two categories of PDE problems, designed to test model performance under various boundary complexities.

Category 1: Externally Prescribed Complex BCs
PDEs: 1D Advection-Reaction, 1D Isothermal Euler, 1D Burgers', 2D Darcy flow.

Characteristics: Time-varying, non-linear boundary conditions without internal feedback.

Generation: PDE_category1/PC1_datageneration/generate_datasets_PDE_task1.py

Description: See PDE_category1/datasets_full/dataset.md and Appendix A of the paper.

Category 2: Complex BCs with Internal-Boundary Coupling and Control
PDEs: Heat Equation with Delayed Integral Feedback, Reaction-Diffusion Equation with Neumann Boundary Integral Feedback, Heat Equation with Non-linear Feedback Gain, Convection-Diffusion Equation with Integral Boundary Control.

Characteristics: Boundary conditions are dynamically coupled with the internal system state and may include external control signals.

Generation: PDE_category2/generate_datasets_PDE_task2.py

Description: See PDE_category2/datasets_new_feedback/dataset.md and Appendix A of the paper.

All datasets include the solution field U(x,t), boundary state information (BC_State), and control signals (BC_Control) where applicable.

üöÄ Getting Started
Prerequisites
Python (3.8+ recommended)

PyTorch (refer to script imports for specific version, e.g., 1.8+ or newer)

NumPy

Matplotlib

SciPy (for some data generation aspects)

Pickle

Argparse

Glob

It is highly recommended to use a Python virtual environment (e.g., conda or venv).

# Example using conda
conda create -n barom_env python=3.9
conda activate barom_env
pip install torch torchvision torchaudio --index-url [https://download.pytorch.org/whl/cu118](https://download.pytorch.org/whl/cu118) # Adjust for your CUDA version
pip install numpy matplotlib scipy argparse

1. Dataset Generation (Optional)
Pre-generated datasets are expected in the respective datasets_full/ and datasets_new_feedback/ directories. If you need to regenerate them:

Category 1 Datasets:

cd PDE_category1/PC1_datageneration/
python generate_datasets_PDE_task1.py --datatype advection # Or euler, burgers, darcy
cd ../.. 

Category 2 Datasets:

cd PDE_category2/
python generate_datasets_PDE_task2.py --datatype heat_nonlinear_feedback_gain # Or other Category 2 types
cd ..

Ensure the output paths in the generation scripts align with where the training/benchmarking scripts expect the data.

2. Training BAROM Models
The primary training scripts are BAROM_ExpBC.py (for the Equation 9 aligned model, mainly for Category 2 PDEs) and BAROM_ImpBC.py (for Category 1 or as a baseline).

Example: Training BAROM_ExpBC (Equation 9 Aligned Model)
This model is typically trained on Category 2 datasets.

python PDE_category2/BAROM_ExpBC.py \
    --datatype heat_nonlinear_feedback_gain \
    --basis_dim 32 \
    --d_model 512 \
    --num_heads 4 \
    --bc_processed_dim 64 \
    --hidden_bc_processor_dim 128 \
    --num_epochs 150 \
    --lr 5e-4 \
    --batch_size 32

Checkpoints will be saved (by default) in a subdirectory within ./New_ckpt_explicit_bc_eq9/ (or as specified in the script).

Example: Training BAROM_ImpBC
This model can be trained on Category 1 or Category 2 datasets.

# For a Category 1 dataset (e.g., Advection)
python PDE_category1/BAROM_ImpBC.py --datatype advection --basis_dim 32 --d_model 256 --num_epochs 150

# For a Category 2 dataset (as a comparison to BAROM_ExpBC)
python PDE_category2/BAROM_ImpBC.py --datatype heat_nonlinear_feedback_gain --basis_dim 32 --d_model 512 --num_epochs 150

Refer to PDE_category1/command_line.md and PDE_category2/command_line.md for more command-line examples and hyperparameter options.

3. Running Benchmarks
Benchmarking scripts are provided to evaluate trained models against baselines.

For Category 1 PDEs: PDE_category1/Benchmarking.py

For Category 2 PDEs: PDE_category2/Benchmarking4GPu.py (includes GPU performance metrics) or the specific benchmarking script you generated for MultiVarAttentionROMEq9.

Example Benchmarking Command (using Benchmarking4GPu.py for Category 2):

python PDE_category2/Benchmarking4GPu.py \
    --datasets heat_nonlinear_feedback_gain reaction_diffusion_neumann_feedback \
    --models BAROM_ExpBC_Eq9 SPFNO LNO # Ensure 'BAROM_ExpBC_Eq9' is a defined key in the script's MODEL_CONFIGS
                                      # pointing to your trained BAROM_ExpBC checkpoint and correct class.

Important: You will need to update the MODEL_CONFIGS dictionary within the benchmark script (Benchmarking4GPu.py or your custom one) to include an entry for your trained MultiVarAttentionROMEq9 model. This entry should specify:

model_class_name: e.g., MultiVarAttentionROMEq9 (or the class name in BAROM_ExpBC.py).

checkpoint_filename_prefix or checkpoint_filename: To locate the saved .pt file. The load_multivar_rom_eq9_model function in the generated benchmark script uses a prefix and glob to find the latest matching checkpoint.

params: The hyperparameters used to train the model, for re-instantiation.

prediction_fn_name: e.g., predict_multivar_rom_eq9.

4. Ablation Studies
Scripts for ablation studies are located in the Ablation_study/ directory.

Run individual ablation training scripts (e.g., Ablation_study/BAROM_Non_attention.py).

Then use corresponding benchmarking scripts (e.g., Ablation_study/Benchmarking_Noatten_BAROM.py or the general Ablation_study/benchmarking.py).
Refer to Ablation_study/ablation.md for descriptions of each study.

üìä Experimental Results
Quantitative results comparing BAROM with baselines are presented in Tables 1, 2, 3, and 4 of the paper. Visual comparisons can be found in Figures 2-7 in the Appendix of the paper. Efficiency metrics (parameters, inference time, GPU memory) are detailed in Appendix F.

Ablation study results are discussed in Section 4.3 and visualized in Figure 3 of the paper.

‚úçÔ∏è Citation
If you use this work, please cite our paper:

@article{YourLastNameYearBAROM,
  title={Latent Space Learning for PDE Systems with Complex Boundary},
  author={Your Name(s) Here},
  journal={Submitted to NeurIPS 2025 (or Conference/Journal Name, or arXiv preprint arXiv:xxxx.xxxxx)},
  year={2024} 
}

(Please replace with your actual publication details once available.)

ü§ù Acknowledgements
(Include any acknowledgements here if applicable.)

‚ùì Questions/Issues
For any questions, bug reports, or issues with the code, please open an issue in this GitHub repository.
